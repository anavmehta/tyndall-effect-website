<!DOCTYPE html>
<html lang="en">

    <head>
        <link rel="stylesheet" href="global.css">
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Tyndall Effect</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap"
            rel="stylesheet">
    </head>

    <body>
        <header>
            <h1>Tyndall Effect</h1>
            <h4>By Anav Mehta, Helena Su, Jared Basilio, and Ge Jin</h4>
        </header>
        <section id="abstract">
            <h2>Abstract</h2>
            <p>
                Through this project, our goal was to render the Tyndall Effect by shooting a ray through a volumetrically
                rendered medium. We approached the problem by first rendering both homogenous and heterogenous fog. We implemented
                ray marching where we had to account for the probabilities of absorption, scattering, and transmittance for each
                step. As for heterogenous fog, we implemented a Perlin Noise to vary the densities when traveling through the
                medium.
            </p>
        </section>
        <section id="technical-approach">
            <h2>Technical Approach</h2>
            <h3>Starting Point & Problem Context</h3>
            <p>
                Our starting point for this project is the CS 184 Project 3 ray tracer. The starting point includes the ray-scene
                intersection, acceleration structure, and physically based lighting and materials. While our starting point able
                to generate realistic images, it lacks of the implementation of spotlight and advanced volumetric rendering
                techniques that are required to depict phenomena like the Tyndall Effect. To address the issues, we expanded the
                render's capabilities by including a complex volumetric rendering,
                implementing both homogenous and heterogeneous fog.
            </p>
            <p>
                The Tyndall Effect is a optical phenomenon where light is scattered by particles that are dispersed in a medium.
                This effect causes the particles, like dust or droplets, become visible when light shines through them.

                In this project, by focusing on rendering fog and cloud effects, we essentially demonstrate the Tyndall Effect.
                Fog, consists of tiny water droplets that suspends in airs, will scatter the light passing through them. Rendering
                fog in various of density provide a clear
            </p>
            <h3>Homogenous Fog</h3>
            <h4>Initial idea</h4>
            <p>
                Initially, our approach to implementing homogenous fog, as suggested by Goodman, involved calculating a distance
                by selecting a uniform random number, ε, within the range [0, 1]. This value was then used to determine the time,
                t, which we interpreted as indicating either a surface or medium intersection. However, we encountered
                difficulties integrating this method with our existing ray tracing code. As a result, we opted for a different
                strategy based on ray marching.
            </p>
            <h4>Ray Marching</h4>
            <p>
                As we know that rays that pass through a medium lose energy due to absorption and out-scattering and gain energy
                due to in-scattering. We represent the scattering interaction through &sigma;<sub>s</sub>
                and the absorption interaction through. Beer-Lambert's Law \[T_{r} = {e^{-\sigma_{t}d}}.\] gives us the
                attenuation of the light traveling through some distance d where \[\sigma_{t} = {\sigma_{a} + \sigma_{s}}.\]As
                we are only dealing with homogenous mediums for now, the density term is constant. Just like how we use BSDFs for
                surface interactions, for media interactions we use a Phase Function since the outgoing direction can now be
                scattered in all directions vs just the hemisphere of directions in surface interactions. For isotropic volumes
                the phase function is simple being 1/4&pi; as it is equally scattered in all directions. However, for anisotropic
                volumes we
                use the Henyey-Greenstein Phase function
                \[p(\theta) = {{1 \over 4\pi}{{1 - g^2} \over [1 + g^2 - 2g*cos(\theta)]^{3/2}}}.\]
                that is parameterized by an asymmetry factor g controlling back and
                front scattering.
            </p>
            <p>
                We can finally put together ray marching as follows:
                <br>
                <br>
                For a certain number of steps, we march the ray's position forward for a chosen step size and for each step we:
            <ol>
                <li>
                    Calculate the fraction of light that is not absorbed or out-scattered traveling a segment of the
                    medium and update the transmission.
                </li>
                <li>
                    We sample the light to find the distance to the light and the direction to the light and calculate the
                    probability we scatter in a certain direction.
                </li>
                <li>
                    Calculate the in-scattering contribution by sampling the light and calculate the attenuation the light ray
                    travels to the point and update the running total of in-scattering light.
                </li>
            </ol>
            </p>
            <h3>Heterogenous Fog</h3>
            <p>
                For Heterogenous fog, the density varies throughout the medium instead of staying constant. To create this density
                field, we implemented a Perlin Noise function that generates smooth, continuous noise that is useful for
                simulating natural phenomena such as Fog.
            </p>
            <h4>Perlin Noise Function</h4>
            <p>
                We implemented our Perlin Noise function by initially generating random normalized vectors that correspond to the
                corners of the 3D cube encompassing each sample point. To increase efficiency and reduce the number of directions
                generated, we used what's called a permutation table which randomly selects gradients to be at each corner of the
                cube. This table is accessed via a hash function hashing the (x, y, z) coordinates of the cube's corners. We
                interpolate between the dot products of the distance vectors—extending from the cube edges to our sample
                point—and the gradient vectors associated with each corner. This interpolation calculates the final noise
                value at the sample point, effectively producing the Perlin Noise.
            </p>

            <h4>Updated Ray Marching</h4>
            <p>
                A Heterogenous medium changes our ray marching algorithm since the densities along our light ray vary as it
                travels through the medium thus our estimation for the in-scattering term is different so we must ray march
                our light ray. While we march our light ray we accumulate density values along each sample along the ray. We
                replace our constant density with our Perlin Noise function and sample at each point for both rays.
            </p>
            <h2>Results</h2>
            <div class="results">
                <div class="image">
                    <img src="./assets/HomogenousFog1.png">
                    <code>Homogenous Fog rendering of ./src/dae/CBSpheres.dae</code>
                </div>
                <div class="image">
                    <img src="./assets/HeterogenousFog1.png">
                    <code>Heterogenous Fog rendering of ./src/dae/CBSpheres.dae</code>
                </div>
            </div>
            <h3>Spot Light Sampling</h3>
            <p>
                We wanted to create realistic soft light beams through the fog to visualize how light scatters through a medium.
                To do this we filled in the spotlight constructor and the associated
                <code>sample_l</code> function. In the <code>sample_l</code>
                function, we calculated the distance to the light by calculating the norm of the difference between the light and
                the object. We got the spot angle
                by getting the negative dot product of the incoming direction and the direction of the light. If our spot angle is
                within the angle of the light,
                we can set the probability distribution function to a uniform spherical distribution pdf and return the radiance
                scaled by some falloff.
                For our project, the falloff was just a simple cosine falloff. Below is the code:
            </p>
            <div class="results">
                <div class="image">
                    <img src="./assets/SpotlightBunny.png">
                    <code>Spotlight on Bunny</code>
                </div>

                <div class="image">
                    <img src="./assets/SpotlightBunnyRedFog.png">
                    <code>Spotlight on Bunny through Red Fog</code>
                </div>

            </div>
        </section>
        <section id="problems-encountered">
            <h2>Problems Encountered</h2>
            <h4>Fog Generation</h4>
            <p>
                When implementing Heterogenous Fog, we had p
            </p>
            <h4>Dae file generation</h4>
            <p>
                Implementing light beams required new having a new
                <code>.dae</code>
                file
                that included a new spot light light rather than an area light or a point light. This was easier said than done.
                Through the Homework 3 Contest Ed Thread, many comments suggested that we hard code our spot light into the
                <code>.dae</code>
                file
                or did the tedious act of modeling our spotlight in Blender 4+, export to Collada (.dae), import into Blender 2.7,
                export to Collada Again,
                then utilize in our renderer. This was very tedious as it required multiple steps to create a singular file. At
                first, we were unsuccessful
                as it only showed a black image or an image that was uniformly lit by the spotlight. We eventually found that
                relative positions for light sources
                were not maintained when reexported. Therefore, changing the light source at the top of any
                <code>.dae</code>
                file
                in prefix with
                <i>CB</i>
                was moved on
                above the box, leading to no light emitting within the box hence the black image. Additionally, the already
                implement
                <code>.dae</code>
                files had
                a CGL rendering technique for the lights. Initially, this influenced some debug approaches that ultimately didn't
                work such as hardcoding the spot lights
                or researching this CGL method described.
            </p>
        </section>
        <section id="lessons-learned">
            <h2>Lessons Learned</h2>
            <p>Understand the underlying math principle first: Debugging the rendering code is hard as there's challenging to
                trace errors back to their source. For instance, in the creating a spotlight, it's essential to understand the
                Monte Carlo Integration on the 3D cone shape object. Without a deep understanding of the math involved,
                identifying the root cause of such problems becomes significantly more complex.
            </p>
            <p>
            </p>
        </section>
        <section id="results">
            <h2>Presentation Video</h2>
            <a href="https://youtu.be/--lKMA1KBt4"></a>
            <p></p>
        </section>
        <section id="Presentation">
            <a href="https://www.youtube.com/watch?v=--lKMA1KBt4">Presentation Video</a>
            <a href=" https://docs.google.com/presentation/d/1fdTJ2BFZyDH3qxRIoOQSyJI1OL9O9ytlayWLHRQ2p2w/edit?usp=sharing">Presentation
                Slides</a>
        </section>
        <section id="references">
            <h2>References</h2>
            <ol>
                <li>
                    <a
                        href="https:
                         //www.scratchapixel.com/lessons/3d-basic-rendering/volume-rendering-for-developers/intro-volume-rendering.html">
                        https://www.scratchapixel.com/lessons/3d-basic-rendering/volume-rendering-for-developers/intro-volume-rendering.html
                    </a>
                </li>
                <li>
                    <a href="https://en.wikipedia.org/wiki/Perlin_noise">https://en.wikipedia.org/wiki/Perlin_noise</a>
                </li>
                <li>
                    <a href="https://inriarhal.scalnce/snnra-00288758i-7
n">https://inria.hal.science/inria-00288758/en</a>
                </li>

                <li>
                    <a href=" https://cseweb.ucsd.edu/~viscomp/classes/cse168/sp20/lectures/168-lecture15.pdf
                    "> https://cseweb.ucsd.edu/~viscomp/classes/cse168/sp20/lectures/168-lecture15.pdf
                    </a>
                </li>
            </ol>
        </section>
        <section id="team-contributions">
            <h2>Contributions from Each Team Member</h2>
            <ul>
                <li>Anav Mehta: Implemented initial Heterogenous and Homogenous Fog code. Implemented Perlin Noise.</li>
                <li>Helena Su: Worked on creating the final deliverable being the heterogenous and homogenous cloud through
                    Rayleigh scattering. </li>
                <li>Jared Basilio: Worked on .dae File Generation Spotlight Approach, HW 3 Source Code</li>
                <li>Ge Jin: Worked on implementing homogenous fog and implementing the spotlight generation </li>
            </ul>
        </section>
    </body>

</html>